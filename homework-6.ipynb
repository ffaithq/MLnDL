{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IMDB sentiment analysis with RNNs\n\nKaggle: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews","metadata":{}},{"cell_type":"markdown","source":"wandb: https://wandb.ai/mlteamaau/ohh%20my%20gosh....%20That%20is%20RNN...?workspace=user-qfaithencz\nKaggle:https://www.kaggle.com/code/eisbarinkaltenpolar/homework-6","metadata":{}},{"cell_type":"code","source":"!python -m nltk.downloader all\nimport subprocess\ntry:\n    nltk.data.find('wordnet.zip')\nexcept:\n    nltk.download('wordnet', download_dir='/kaggle/working/')\n    command = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\n    subprocess.run(command.split())\n    nltk.data.path.append('/kaggle/working/')","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pyspellchecker","metadata":{"execution":{"iopub.status.busy":"2024-01-29T14:40:43.508632Z","iopub.execute_input":"2024-01-29T14:40:43.508991Z","iopub.status.idle":"2024-01-29T14:40:53.310849Z","shell.execute_reply.started":"2024-01-29T14:40:43.508961Z","shell.execute_reply":"2024-01-29T14:40:53.309969Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyspellchecker in /opt/conda/lib/python3.10/site-packages (0.8.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom sklearn.model_selection import train_test_split\nfrom spellchecker import SpellChecker\nfrom tqdm import tqdm\n# allows to have a progress bar in pandas, useful for long processing operations\ntqdm.pandas()\nfrom collections import Counter\nimport torch\nfrom torch import nn\nfrom torch.utils.data import TensorDataset, DataLoader\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:41:01.216942Z","iopub.execute_input":"2024-01-29T14:41:01.217290Z","iopub.status.idle":"2024-01-29T14:41:03.694339Z","shell.execute_reply.started":"2024-01-29T14:41:01.217264Z","shell.execute_reply":"2024-01-29T14:41:03.693510Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Read the dataset and observe the first 5 rows.","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\ndata.head()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:41:26.659931Z","iopub.execute_input":"2024-01-29T14:41:26.660284Z","iopub.status.idle":"2024-01-29T14:41:27.257221Z","shell.execute_reply.started":"2024-01-29T14:41:26.660260Z","shell.execute_reply":"2024-01-29T14:41:27.256430Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Lucky us, the dataset is well-balanced.","metadata":{}},{"cell_type":"code","source":"data.sentiment.value_counts()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:41:30.246873Z","iopub.execute_input":"2024-01-29T14:41:30.247264Z","iopub.status.idle":"2024-01-29T14:41:30.257241Z","shell.execute_reply.started":"2024-01-29T14:41:30.247231Z","shell.execute_reply":"2024-01-29T14:41:30.256290Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"sentiment\npositive    25000\nnegative    25000\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"Transform the labels to 0 and 1.","metadata":{}},{"cell_type":"code","source":"def transform_label(label):\n    return 1 if label == 'positive' else 0\n\n\ndata['label'] = data['sentiment'].progress_apply(transform_label)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:41:33.467784Z","iopub.execute_input":"2024-01-29T14:41:33.468279Z","iopub.status.idle":"2024-01-29T14:41:33.542188Z","shell.execute_reply.started":"2024-01-29T14:41:33.468255Z","shell.execute_reply":"2024-01-29T14:41:33.541167Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"100%|██████████| 50000/50000 [00:00<00:00, 769117.25it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Preprocessing\n\n- In classic NLP, the text is often preprocessed to remove tokens that might confuse the classifier\n- Below you can find some examples of possible preprocessing techniques\n- Feel free to modify them to improve the results of your classifier","metadata":{}},{"cell_type":"code","source":"nltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('punkt')\nnltk.download('omw-1.4')\nstopwords = set(stopwords.words('english'))\n\ndef rm_link(text):\n    return re.sub(r'http\\S+', '', text)\n\n\n# handle case like \"shut up okay?Im only 10 years old\"\n# become \"shut up okay Im only 10 years old\"\ndef rm_punct2(text):\n    # return re.sub(r'[\\!\\\"\\#\\$\\%\\&\\'\\(\\)\\*\\+\\,\\-\\.\\/\\:\\;\\<\\=\\>\\?\\@\\[\\\\\\]\\^\\_\\`\\{\\|\\}\\~]', ' ', text)\n    return re.sub(r'[\\\"\\#\\$\\%\\&\\'\\(\\)\\*\\+\\/\\:\\;\\<\\=\\>\\@\\[\\\\\\]\\^\\_\\`\\{\\|\\}\\~]', ' ', text)\n\n\ndef rm_html(text):\n    # remove html tags\n    text = re.sub(r'<.*?>', '', text)\n    # remove <br /> tags\n    return re.sub(r'<br />', '', text)\n\n\ndef space_bt_punct(text):\n    pattern = r'([.,!?-])'\n    s = re.sub(pattern, r' \\1 ', text)  # add whitespaces between punctuation\n    s = re.sub(r'\\s{2,}', ' ', s)  # remove double whitespaces\n    return s\n\n\ndef rm_number(text):\n    return re.sub(r'\\d+', '', text)\n\n\ndef rm_whitespaces(text):\n    return re.sub(r'\\s+', ' ', text)\n\n\ndef rm_nonascii(text):\n    return re.sub(r'[^\\x00-\\x7f]', r'', text)\n\n\ndef rm_emoji(text):\n    emojis = re.compile(\n        '['\n        u'\\U0001F600-\\U0001F64F'  # emoticons\n        u'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n        u'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n        u'\\U0001F1E0-\\U0001F1FF'  # flags (iOS)\n        u'\\U00002702-\\U000027B0'\n        u'\\U000024C2-\\U0001F251'\n        ']+',\n        flags=re.UNICODE\n    )\n    return emojis.sub(r'', text)\n\n\ndef spell_correction(text):\n    # if too slow: return text\n    return text\n    # https://pypi.org/project/pyspellchecker/\n    spell = SpellChecker()\n    corrected_text = []\n    misspelled_words = spell.unknown(text.split())\n    for word in text.split():\n        if word in misspelled_words:\n            candidate = spell.correction(word)\n            if candidate is not None:\n                corrected_text.append(candidate)\n            else:\n                corrected_text.append(word)\n        else:\n            corrected_text.append(word)\n    return ' '.join(corrected_text)\n\ndef clean_pipeline(text):\n    text = text.lower()\n    no_link = rm_link(text)\n    no_html = rm_html(no_link)\n    space_punct = space_bt_punct(no_html)\n    no_punct = rm_punct2(space_punct)\n    no_number = rm_number(no_punct)\n    no_whitespaces = rm_whitespaces(no_number)\n    no_nonasci = rm_nonascii(no_whitespaces)\n    no_emoji = rm_emoji(no_nonasci)\n    spell_corrected = spell_correction(no_emoji)\n    return spell_corrected","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:41:35.926704Z","iopub.execute_input":"2024-01-29T14:41:35.927027Z","iopub.status.idle":"2024-01-29T14:41:36.028736Z","shell.execute_reply.started":"2024-01-29T14:41:35.927004Z","shell.execute_reply":"2024-01-29T14:41:36.027613Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let's clean the reviews first:","metadata":{}},{"cell_type":"code","source":"data['review'] = data['review'].progress_apply(clean_pipeline)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:41:40.020790Z","iopub.execute_input":"2024-01-29T14:41:40.021129Z","iopub.status.idle":"2024-01-29T14:41:51.489303Z","shell.execute_reply.started":"2024-01-29T14:41:40.021105Z","shell.execute_reply":"2024-01-29T14:41:51.488429Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"100%|██████████| 50000/50000 [00:11<00:00, 4364.03it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We now tokenize and remove stopwords (i.e. the, a, an, etc.) and lemmatize the words (i.e. running -> run, better -> good, etc.).","metadata":{}},{"cell_type":"code","source":"# preprocessing\ndef tokenize(text):\n    return word_tokenize(text)\n\n\ndef rm_stopwords(text):\n    return [i for i in text if i not in stopwords]\n\n\ndef lemmatize(text):\n    lemmatizer = WordNetLemmatizer()\n    lemmas = [lemmatizer.lemmatize(t) for t in text]\n    # make sure lemmas does not contains stopwords\n    return rm_stopwords(lemmas)\n\n\ndef preprocess_pipeline(text):\n    tokens = tokenize(text)\n    no_stopwords = rm_stopwords(tokens)\n    lemmas = lemmatize(no_stopwords)\n    return ' '.join(lemmas)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:41:55.399109Z","iopub.execute_input":"2024-01-29T14:41:55.399428Z","iopub.status.idle":"2024-01-29T14:41:55.404838Z","shell.execute_reply.started":"2024-01-29T14:41:55.399405Z","shell.execute_reply":"2024-01-29T14:41:55.403937Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data['review'] = data['review'].progress_apply(preprocess_pipeline)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:41:58.282862Z","iopub.execute_input":"2024-01-29T14:41:58.283240Z","iopub.status.idle":"2024-01-29T14:43:58.799387Z","shell.execute_reply.started":"2024-01-29T14:41:58.283211Z","shell.execute_reply":"2024-01-29T14:43:58.798399Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"100%|██████████| 50000/50000 [02:00<00:00, 414.94it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let's check the result.","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:44:32.435642Z","iopub.execute_input":"2024-01-29T14:44:32.436266Z","iopub.status.idle":"2024-01-29T14:44:32.444836Z","shell.execute_reply.started":"2024-01-29T14:44:32.436235Z","shell.execute_reply":"2024-01-29T14:44:32.444179Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment  label\n0  one reviewer mentioned watching oz episode hoo...  positive      1\n1  wonderful little production . filming techniqu...  positive      1\n2  thought wonderful way spend time hot summer we...  positive      1\n3  basically family little boy jake think zombie ...  negative      0\n4  petter mattei love time money visually stunnin...  positive      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one reviewer mentioned watching oz episode hoo...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>wonderful little production . filming techniqu...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>thought wonderful way spend time hot summer we...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically family little boy jake think zombie ...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter mattei love time money visually stunnin...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Embedding\n\n- ANNs cannot process text input\n- Input tokens must be mapped to integers using a vocabulary\n- In this example, we build a vocabulary manually, but you can also replace this code with an [embedding layer](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html)","metadata":{}},{"cell_type":"code","source":"# get all processed reviews\nreviews = data.review.values\n# merge into single variable, separated by whitespaces\nwords = ' '.join(reviews)\n# obtain list of words\nwords = words.split()\n# build vocabulary\ncounter = Counter(words)\n# only keep top 2000 words\nvocab = sorted(counter, key=counter.get, reverse=True)[:2000]\nint2word = dict(enumerate(vocab, 2))\nint2word[0] = '<PAD>'\nint2word[1] = '<UNK>'\nword2int = {word: id for id, word in int2word.items()}","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:44:34.909108Z","iopub.execute_input":"2024-01-29T14:44:34.909430Z","iopub.status.idle":"2024-01-29T14:44:36.534318Z","shell.execute_reply.started":"2024-01-29T14:44:34.909407Z","shell.execute_reply":"2024-01-29T14:44:36.533592Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"reviews_enc = [[word2int[word] if word in word2int else word2int['<UNK>'] for word in review.split()] for review in tqdm(reviews, desc='encoding')]","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:44:40.919910Z","iopub.execute_input":"2024-01-29T14:44:40.920443Z","iopub.status.idle":"2024-01-29T14:44:42.487479Z","shell.execute_reply.started":"2024-01-29T14:44:40.920415Z","shell.execute_reply":"2024-01-29T14:44:42.486625Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"encoding: 100%|██████████| 50000/50000 [00:01<00:00, 32067.67it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Because we have to build batch, we have to pad the reviews to the same length. We will pad the reviews with <PAD> token.\n**Because we use RNNs, we need to left pad and not right pad the sequence.**","metadata":{}},{"cell_type":"code","source":"# left padding sequences\ndef pad_features(reviews, pad_id, seq_length=128):\n    # features = np.zeros((len(reviews), seq_length), dtype=int)\n    features = np.full((len(reviews), seq_length), pad_id, dtype=int)\n\n    for i, row in enumerate(reviews):\n        start_index = max(0, seq_length - len(row))\n        # if seq_length < len(row) then review will be trimmed\n        features[i, start_index:] = np.array(row)[:min(seq_length, len(row))]\n\n    return features\n\n\nseq_length = 128\nfeatures = pad_features(reviews_enc, pad_id=word2int['<PAD>'], seq_length=seq_length)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:44:45.559883Z","iopub.execute_input":"2024-01-29T14:44:45.560198Z","iopub.status.idle":"2024-01-29T14:44:45.931100Z","shell.execute_reply.started":"2024-01-29T14:44:45.560175Z","shell.execute_reply":"2024-01-29T14:44:45.930225Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Split the data","metadata":{}},{"cell_type":"code","source":"labels = data.label.to_numpy()\n\n# train test split\ntrain_size = .75  # we will use 75% of whole data as train set\nval_size = .5  # and we will use 50% of test set as validation set\n\n# stratify will make sure that train and test set have same distribution of labels\ntrain_x, test_x, train_y, test_y = train_test_split(features, labels, test_size=1 - train_size, stratify=labels)\n\n# split test set into validation and test set\nval_x, test_x, val_y, test_y = train_test_split(test_x, test_y, test_size=val_size, stratify=test_y)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:44:49.324608Z","iopub.execute_input":"2024-01-29T14:44:49.324956Z","iopub.status.idle":"2024-01-29T14:44:49.372284Z","shell.execute_reply.started":"2024-01-29T14:44:49.324925Z","shell.execute_reply":"2024-01-29T14:44:49.371424Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Define the datasets and dataloaders.","metadata":{}},{"cell_type":"code","source":"# define batch size\nbatch_size = 128\n\n# create tensor datasets\ntrain_dataset = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\nvalid_dataset = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\ntest_dataset = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n\n# create dataloaders\ntrain_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\nvalid_loader = DataLoader(valid_dataset, shuffle=True, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:44:51.776071Z","iopub.execute_input":"2024-01-29T14:44:51.776745Z","iopub.status.idle":"2024-01-29T14:44:51.782979Z","shell.execute_reply.started":"2024-01-29T14:44:51.776707Z","shell.execute_reply":"2024-01-29T14:44:51.782353Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Define the model.","metadata":{}},{"cell_type":"code","source":"from torch.nn import functional as F","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNNModel(nn.Module):\n    def __init__(self,vocab_size,hidden_dim,num_layers,embedding_dim, **kwargs):\n        super(RNNModel, self).__init__(**kwargs)\n        self.hidden_dim = hidden_dim\n        self.vocab_size = vocab_size\n        self.num_layer = num_layers\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_dim,num_layers=num_layers,nonlinearity='tanh',batch_first=True)\n        self.linear = nn.Linear(self.hidden_dim, 1)\n        self.dummy_param = nn.Parameter(torch.empty(0))\n        \n    def forward(self, inputs, state):\n        X = self.embedding(inputs)\n        X = X.to(torch.float32)\n        \n        Y, state = self.rnn(X, state)\n        output = nn.Sigmoid()(self.linear(Y))[:,-1]\n        return output, state\n\n    def begin_state(self, batch_size=1):\n        return torch.zeros((self.rnn.num_layers,\n                                 batch_size, self.hidden_dim),\n                                 device=self.dummy_param.device)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:44:55.628382Z","iopub.execute_input":"2024-01-29T14:44:55.628725Z","iopub.status.idle":"2024-01-29T14:44:55.637408Z","shell.execute_reply.started":"2024-01-29T14:44:55.628699Z","shell.execute_reply":"2024-01-29T14:44:55.636569Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Instantiate the model.","metadata":{}},{"cell_type":"markdown","source":"Define the loss function and optimizer.","metadata":{}},{"cell_type":"code","source":"num_hiddens = 16\nnet = RNNModel(vocab_size = len(word2int),hidden_dim = num_hiddens,num_layers = 2, embedding_dim = 128)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:44:58.205697Z","iopub.execute_input":"2024-01-29T14:44:58.206014Z","iopub.status.idle":"2024-01-29T14:44:58.213985Z","shell.execute_reply.started":"2024-01-29T14:44:58.205990Z","shell.execute_reply":"2024-01-29T14:44:58.213282Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Define the training loop.","metadata":{}},{"cell_type":"code","source":"from tqdm.notebook import trange, tqdm\n#import wandb\n#wandb.login()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T14:45:01.260376Z","iopub.execute_input":"2024-01-29T14:45:01.260697Z","iopub.status.idle":"2024-01-29T14:45:03.946839Z","shell.execute_reply.started":"2024-01-29T14:45:01.260674Z","shell.execute_reply":"2024-01-29T14:45:03.945992Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqfaithencz\u001b[0m (\u001b[33mmlteamaau\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"epochs = 25\ncriteria = nn.BCELoss()\noptim = torch.optim.Adam(net.parameters())\n\n'''\nwandb.init(\n    project='ohh my gosh.... That is RNN...',\n    config={\n        \"epochs\": epochs,\n        \"batch_size\": batch_size,\n        \"optimizer\": \"Adam\",\n        \"criterion\": \"BCELoss\",\n        \"learning rate\": \"default\",\n    },\n    name = \"Can you just work....?( (Pytorch embedded)\"\n)\n\n'''\n\n\n\nfor epoch in trange(epochs):\n    loss, n,accuracy = 0.0, 0,0.0\n    \n    net.train()\n    for X, Y in train_loader:\n        state = net.begin_state(batch_size=len(Y))\n        (output, state) = net(X, state)\n        y = Y.reshape(-1,1)\n        output = output.to(torch.float32)\n        output = output[:len(y),:] # last batch is smaller. 124 samples \n        y = y.to(torch.float32)\n        l = criteria(output, y) # \n        optim.zero_grad()\n        l.backward()\n        optim.step()\n        accuracy += (torch.round(output) == y).float().mean().item()\n        loss += l.item()\n    '''\n        wandb.log({\n            'train loss': loss / len(train_loader),\n            'train accuracy': accuracy / len(train_loader)\n        }, step=epoch+1)\n    '''\n\n\n    net.eval()\n    loss, n,accuracy= 0.0, 0,0.0\n    for X, Y in valid_loader:\n        with torch.no_grad():\n            state = net.begin_state(batch_size=len(Y))\n            (output, state) = net(X, state)\n            y = Y.reshape(-1,1)\n            output = output.to(torch.float32)\n            output = output[:len(y),:] # last batch is smaller. 124 samples \n            y = y.to(torch.float32)\n            l = criteria(output, y) # \n            loss += l.item()\n            accuracy += (torch.round(output) == y).float().mean().item()\n            '''\n                wandb.log({\n            'valid loss': loss / len(valid_loader),\n            'valid accuracy': accuracy / len(valid_loader)\n        },step=epoch+1)\n            '''\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T14:45:07.076802Z","iopub.execute_input":"2024-01-29T14:45:07.077391Z","iopub.status.idle":"2024-01-29T14:49:32.608409Z","shell.execute_reply.started":"2024-01-29T14:45:07.077363Z","shell.execute_reply":"2024-01-29T14:49:32.607510Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240129_144507-gk4tgjrg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/mlteamaau/ohh%20my%20gosh....%20That%20is%20RNN.../runs/gk4tgjrg' target=\"_blank\">Can you just work....?( (Pytorch embedded)</a></strong> to <a href='https://wandb.ai/mlteamaau/ohh%20my%20gosh....%20That%20is%20RNN...' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/mlteamaau/ohh%20my%20gosh....%20That%20is%20RNN...' target=\"_blank\">https://wandb.ai/mlteamaau/ohh%20my%20gosh....%20That%20is%20RNN...</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/mlteamaau/ohh%20my%20gosh....%20That%20is%20RNN.../runs/gk4tgjrg' target=\"_blank\">https://wandb.ai/mlteamaau/ohh%20my%20gosh....%20That%20is%20RNN.../runs/gk4tgjrg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f790926864a4b78ae31587f4fd93448"}},"metadata":{}}]},{"cell_type":"markdown","source":"Evaluate the model on the test set.","metadata":{}},{"cell_type":"markdown","source":"With Hand made embedded layer","metadata":{}},{"cell_type":"code","source":"loss, n,accuracy = 0.0, 0,0.0\nstate = net.begin_state(batch_size=batch_size)\nnet.eval()\nfor X, Y in test_loader:\n    with torch.no_grad():\n        state = net.begin_state(batch_size=batch_size)\n        (output, state) = net(X, state)\n        y = Y.reshape(-1,1)\n        output = output.to(torch.float32)\n        output = output[:len(y),:] # last batch is smaller. 124 samples \n        y = y.to(torch.float32)\n        l = criteria(output, y) # \n        loss += l.item()\n        accuracy += (torch.round(output) == y).float().mean().item()\nprint(f\"test loss {loss/len(test_loader)}, test accuracy {accuracy/len(test_loader)}\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"loss = 0.7 | acc: 0.5","metadata":{}},{"cell_type":"markdown","source":"Pytorch embedded","metadata":{}},{"cell_type":"code","source":"loss, n,accuracy = 0.0, 0,0.0\nstate = net.begin_state(batch_size=batch_size)\nnet.eval()\nfor X, Y in test_loader:\n    with torch.no_grad():\n        state = net.begin_state(batch_size=len(Y))\n        (output, state) = net(X, state)\n        y = Y.reshape(-1,1)\n        output = output.to(torch.float32)\n        output = output[:len(y),:] # last batch is smaller. 124 samples \n        y = y.to(torch.float32)\n        l = criteria(output, y) # \n        loss += l.item()\n        accuracy += (torch.round(output) == y).float().mean().item()\nprint(f\"test loss {loss/len(test_loader)}, test accuracy {accuracy/len(test_loader)}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-29T14:50:33.973501Z","iopub.execute_input":"2024-01-29T14:50:33.973909Z","iopub.status.idle":"2024-01-29T14:50:34.385579Z","shell.execute_reply.started":"2024-01-29T14:50:33.973877Z","shell.execute_reply":"2024-01-29T14:50:34.384510Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"test loss 0.5366604352483944, test accuracy 0.7584803384177539\n","output_type":"stream"}]}]}