{"cells":[{"cell_type":"markdown","metadata":{},"source":["Kaggle: https://www.kaggle.com/code/eisbarinkaltenpolar/homework-5\n","Wandb: https://wandb.ai/mlteamaau/pretraining-resnet18?workspace=user-qfaithencz"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-21T13:35:08.264670Z","iopub.status.busy":"2024-01-21T13:35:08.263750Z","iopub.status.idle":"2024-01-21T13:35:08.621315Z","shell.execute_reply":"2024-01-21T13:35:08.620440Z","shell.execute_reply.started":"2024-01-21T13:35:08.264636Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/cifar-10/trainLabels.csv\n","/kaggle/input/cifar-10/sampleSubmission.csv\n","/kaggle/input/cifar-10/test.7z\n","/kaggle/input/cifar-10/train.7z\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["## Import everything needed"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T13:35:10.509276Z","iopub.status.busy":"2024-01-21T13:35:10.508795Z","iopub.status.idle":"2024-01-21T13:35:17.098559Z","shell.execute_reply":"2024-01-21T13:35:17.097710Z","shell.execute_reply.started":"2024-01-21T13:35:10.509245Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import glob\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import collections\n","import math\n","import os\n","import shutil\n","from sklearn.model_selection import train_test_split\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision\n","from torchvision import datasets, transforms\n","np.random.seed(0)\n","torch.manual_seed(0)\n","torch.cuda.manual_seed(0)"]},{"cell_type":"markdown","metadata":{},"source":["## Unzip datasets"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T13:35:17.100810Z","iopub.status.busy":"2024-01-21T13:35:17.100286Z","iopub.status.idle":"2024-01-21T13:35:35.239681Z","shell.execute_reply":"2024-01-21T13:35:35.238526Z","shell.execute_reply.started":"2024-01-21T13:35:17.100775Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting py7zr\n","  Obtaining dependency information for py7zr from https://files.pythonhosted.org/packages/c0/39/71263be4c6081e1788f4da35e937fca1808914b0d98a04bd44255b948699/py7zr-0.20.8-py3-none-any.whl.metadata\n","  Downloading py7zr-0.20.8-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.7.0)\n","Collecting pycryptodomex>=3.16.0 (from py7zr)\n","  Obtaining dependency information for pycryptodomex>=3.16.0 from https://files.pythonhosted.org/packages/20/7a/3162173af8597f0399b45c6aaa4939ccae908476fdf1b3a3cc30631fc9fb/pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Collecting pyzstd>=0.15.9 (from py7zr)\n","  Obtaining dependency information for pyzstd>=0.15.9 from https://files.pythonhosted.org/packages/02/97/57de14ccb0d033464aabc5110eb2f9dc717c97e17f2ffc1235680a27e5de/pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n","Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\n","  Obtaining dependency information for pyppmd<1.2.0,>=1.1.0 from https://files.pythonhosted.org/packages/09/76/61db4268a439cfba8736b14130d928d199633fab2360a2c5043332a427d2/pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n","Collecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n","  Obtaining dependency information for pybcj<1.1.0,>=1.0.0 from https://files.pythonhosted.org/packages/09/70/8b6a6cc2a5721f67f629bdc17875c0d603d57f360a19b099a7b4de19383d/pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n","Collecting multivolumefile>=0.2.3 (from py7zr)\n","  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n","Collecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n","  Obtaining dependency information for inflate64<1.1.0,>=1.0.0 from https://files.pythonhosted.org/packages/b8/f4/e387a50f5027194eac4f9712d57b97e3e1a012402eaae98bcf1ebe8a97d1/inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n","Collecting brotli>=1.1.0 (from py7zr)\n","  Obtaining dependency information for brotli>=1.1.0 from https://files.pythonhosted.org/packages/d5/00/40f760cc27007912b327fe15bf6bfd8eaecbe451687f72a8abc587d503b3/Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata\n","  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from py7zr) (5.9.3)\n","Downloading py7zr-0.20.8-py3-none-any.whl (67 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr\n","Successfully installed brotli-1.1.0 inflate64-1.0.0 multivolumefile-0.2.3 py7zr-0.20.8 pybcj-1.0.2 pycryptodomex-3.20.0 pyppmd-1.1.0 pyzstd-0.15.9\n"]}],"source":["!pip install py7zr"]},{"cell_type":"markdown","metadata":{},"source":["# WARNING: It can take a lot of time to uncompress!"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T13:38:24.430219Z","iopub.status.busy":"2024-01-21T13:38:24.429281Z","iopub.status.idle":"2024-01-21T13:39:23.778198Z","shell.execute_reply":"2024-01-21T13:39:23.777066Z","shell.execute_reply.started":"2024-01-21T13:38:24.430180Z"},"trusted":true},"outputs":[],"source":["!python -m py7zr x /kaggle/input/cifar-10/train.7z"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T13:39:23.780318Z","iopub.status.busy":"2024-01-21T13:39:23.780033Z","iopub.status.idle":"2024-01-21T13:58:52.283868Z","shell.execute_reply":"2024-01-21T13:58:52.282202Z","shell.execute_reply.started":"2024-01-21T13:39:23.780290Z"},"trusted":true},"outputs":[],"source":["!python -m py7zr x /kaggle/input/cifar-10/test.7z"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T13:59:08.519969Z","iopub.status.busy":"2024-01-21T13:59:08.519564Z","iopub.status.idle":"2024-01-21T13:59:08.524791Z","shell.execute_reply":"2024-01-21T13:59:08.523869Z","shell.execute_reply.started":"2024-01-21T13:59:08.519930Z"},"trusted":true},"outputs":[],"source":["data_dir = '/kaggle/working/'"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T13:59:10.778008Z","iopub.status.busy":"2024-01-21T13:59:10.777076Z","iopub.status.idle":"2024-01-21T13:59:10.869883Z","shell.execute_reply":"2024-01-21T13:59:10.868841Z","shell.execute_reply.started":"2024-01-21T13:59:10.777965Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number training examples: 50000\n","Number classes: 10\n"]}],"source":["def read_csv_labels(fname):\n","    \"\"\"Read `fname` to return a filename to label dictionary.\"\"\"\n","    with open(fname, 'r') as f:\n","        # Skip the file header line (column name)\n","        lines = f.readlines()[1:]\n","    tokens = [l.rstrip().split(',') for l in lines]\n","    return dict(((name, label) for name, label in tokens))\n","\n","labels = read_csv_labels(os.path.join(data_dir, '/kaggle/input/cifar-10/trainLabels.csv'))\n","print(f'Number training examples: {len(labels)}')\n","print(f'Number classes: {len(set(labels.values()))}')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T13:59:13.990230Z","iopub.status.busy":"2024-01-21T13:59:13.989821Z","iopub.status.idle":"2024-01-21T13:59:14.002508Z","shell.execute_reply":"2024-01-21T13:59:14.001742Z","shell.execute_reply.started":"2024-01-21T13:59:13.990197Z"},"trusted":true},"outputs":[],"source":["def copyfile(filename, target_dir):\n","    \"\"\"Copy a file into a target directory.\"\"\"\n","    os.makedirs(target_dir, exist_ok=True)\n","    shutil.copy(filename, target_dir)\n","\n","def reorg_train_valid(data_dir, labels, valid_ratio):\n","    \"\"\"Split the validation set out of the original training set.\"\"\"\n","    # The number of examples of the class that has the fewest examples in the\n","    # training dataset\n","    n = collections.Counter(labels.values()).most_common()[-1][1]\n","    # The number of examples per class for the validation set\n","    n_valid_per_label = max(1, math.floor(n * valid_ratio))\n","    label_count = {}\n","    for train_file in os.listdir(os.path.join(data_dir, 'train')):\n","        label = labels[train_file.split('.')[0]]\n","        fname = os.path.join(data_dir, 'train', train_file)\n","        copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n","                                     'train_valid', label))\n","        if label not in label_count or label_count[label] < n_valid_per_label:\n","            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n","                                         'valid', label))\n","            label_count[label] = label_count.get(label, 0) + 1\n","        else:\n","            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n","                                         'train', label))\n","    return n_valid_per_label\n","\n","def reorg_test(data_dir):\n","    \"\"\"Organize the testing set for data loading during prediction.\"\"\"\n","    for test_file in os.listdir(os.path.join(data_dir, 'test')):\n","        copyfile(os.path.join(data_dir, 'test', test_file),\n","                 os.path.join(data_dir, 'train_valid_test', 'test',\n","                              'unknown'))\n","        \n","def reorg_cifar10_data(data_dir, valid_ratio):\n","    labels = read_csv_labels('/kaggle/input/cifar-10/trainLabels.csv')\n","    reorg_train_valid(data_dir, labels, valid_ratio)\n","    reorg_test(data_dir)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T14:00:53.520379Z","iopub.status.busy":"2024-01-21T14:00:53.520008Z","iopub.status.idle":"2024-01-21T14:01:56.549269Z","shell.execute_reply":"2024-01-21T14:01:56.548455Z","shell.execute_reply.started":"2024-01-21T14:00:53.520346Z"},"trusted":true},"outputs":[],"source":["batch_size = 512\n","valid_ratio = 0.1\n","reorg_cifar10_data(data_dir, valid_ratio)"]},{"cell_type":"markdown","metadata":{},"source":["### Transformations\n","- Pre-trained networks usually apply some transformations to their inputs\n","- TODOs:\n","    - Check the transformations in the pre-trained ResNet and sync with yours! \n","    - Consider adding more transformations, like HorizontalFlip, mnRandomSizeCrop"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T15:36:46.697144Z","iopub.status.busy":"2024-01-21T15:36:46.696192Z","iopub.status.idle":"2024-01-21T15:36:46.704016Z","shell.execute_reply":"2024-01-21T15:36:46.703060Z","shell.execute_reply.started":"2024-01-21T15:36:46.697099Z"},"trusted":true},"outputs":[],"source":["\n","transform_norm = torchvision.transforms.Compose([\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n","                                     [0.2023, 0.1994, 0.2010])\n","])\n","\n","transform_train = torchvision.transforms.Compose([\n","    torchvision.transforms.RandomResizedCrop(size=(32, 32),scale=(0.08, 1.0), ratio=(0.5,1.25), antialias=True),\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n","                                     [0.2023, 0.1994, 0.2010])\n","])"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T15:36:49.912671Z","iopub.status.busy":"2024-01-21T15:36:49.912158Z","iopub.status.idle":"2024-01-21T15:36:51.888570Z","shell.execute_reply":"2024-01-21T15:36:51.887752Z","shell.execute_reply.started":"2024-01-21T15:36:49.912636Z"},"trusted":true},"outputs":[],"source":["train_ds, train_valid_ds = [torchvision.datasets.ImageFolder(\n","    os.path.join(data_dir, 'train_valid_test', folder),\n","    transform=transform_train) for folder in ['train', 'train_valid']]\n","\n","valid_ds, test_ds = [torchvision.datasets.ImageFolder(\n","    os.path.join(data_dir, 'train_valid_test', folder),\n","    transform=transform_norm) for folder in ['valid', 'test']]\n","\n","\n","train_iter, train_valid_iter = [torch.utils.data.DataLoader(\n","    dataset, batch_size, shuffle=True, drop_last=True)\n","    for dataset in (train_ds, train_valid_ds)]\n","\n","\n","valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,\n","                                         drop_last=True)\n","\n","test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,\n","                                        drop_last=False)"]},{"cell_type":"markdown","metadata":{},"source":["## TODO: \n","* Define the data augmentation technique \n","* Fine-tune a pre-trained ResNet-18 on CIFAR-10\n","* Submit your submission file to Kaggle (as described in the competition rules) and get your accuracy on the test set"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T15:42:32.024836Z","iopub.status.busy":"2024-01-21T15:42:32.024458Z","iopub.status.idle":"2024-01-21T15:42:32.242349Z","shell.execute_reply":"2024-01-21T15:42:32.241292Z","shell.execute_reply.started":"2024-01-21T15:42:32.024807Z"},"trusted":true},"outputs":[],"source":["pretrained_net = torchvision.models.resnet18(pretrained=True)\n","pretrained_net.fc = nn.Linear(pretrained_net.fc.in_features, 10)\n","nn.init.xavier_normal_(pretrained_net.fc.weight)\n","nn.init.constant_(pretrained_net.fc.bias, 0)\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","pretrained_net = pretrained_net.to(device)\n","if device == 'cuda':\n","    pretrained_net = torch.nn.DataParallel(pretrained_net) # if multiple GPUs use them\n","\n","config = dict(\n","  epochs=20,\n","  classes=10,\n","  model = pretrained_net,\n","  optimizer = torch.optim.Adam(pretrained_net.parameters()),\n","  loss = nn.CrossEntropyLoss(),\n","  batch_size=batch_size,\n","  learning_rate=\"default\",\n","  dataset=\"CIFAR10\",\n","  architecture=\"ResNet-18\",\n","  run = \"With resize crop scale=(0.08, 1.0), ratio=(0.5,1.25)\",\n","  device = device,\n",")\n","\n","\n","\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(config[\"optimizer\"], 'min', patience=3, verbose=True, min_lr=1e-5, factor=0.5)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T14:49:01.329957Z","iopub.status.busy":"2024-01-21T14:49:01.329251Z","iopub.status.idle":"2024-01-21T14:49:01.335999Z","shell.execute_reply":"2024-01-21T14:49:01.334931Z","shell.execute_reply.started":"2024-01-21T14:49:01.329923Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"]}],"source":["#import wandb\n","#wandb.login()\n","from tqdm.notebook import trange, tqdm\n","run = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T15:42:37.562260Z","iopub.status.busy":"2024-01-21T15:42:37.561857Z","iopub.status.idle":"2024-01-21T16:06:13.792534Z","shell.execute_reply":"2024-01-21T16:06:13.791495Z","shell.execute_reply.started":"2024-01-21T15:42:37.562226Z"}},"outputs":[],"source":["run += 1\n","wandb.init(project=\"pretraining-resnet18\", config = config, name = config[\"run\"])\n","\n","epochs = config[\"epochs\"]\n","optimizer = config[\"optimizer\"]\n","criterion = config[\"loss\"]\n","\n","for epoch in trange(epochs):\n","    \n","    accuracy_train = 0\n","    total_train = 0\n","    losses_train = 0\n","    \n","    pretrained_net.train()\n","    for X, y in train_iter:\n","        X = X.to(device)\n","        y = y.to(device)\n","        y_pred = pretrained_net(X)\n","        loss = criterion(y_pred, y)\n","        predicted = torch.argmax(y_pred, 1)\n","        accuracy_train += (y == predicted).sum().float()\n","        losses_train += loss.item()\n","        total_train += len(y)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    \n","    valid_accuracy_aug = 0\n","    valid_total_aug = 0\n","    valid_losses_aug = 0\n","    \n","    #clear \n","    pretrained_net.eval()\n","    with torch.no_grad():\n","        for X, y in train_valid_iter:\n","            X = X.to(device)\n","            y = y.to(device)\n","            y_pred = pretrained_net(X)\n","            loss = criterion(y_pred, y)\n","            predicted = torch.argmax(y_pred, 1)\n","            valid_accuracy_aug += (y == predicted).sum().float()\n","            valid_losses_aug += loss.item()\n","            valid_total_aug += len(y)\n","    \n","    \n","    valid_acc = 0\n","    valid_total = 0\n","    valid_losses = 0\n","    \n","    pretrained_net.eval()\n","    with torch.no_grad():\n","        for X, y in valid_iter:\n","            X = X.to(device)\n","            y = y.to(device)\n","            y_pred = pretrained_net(X)\n","            loss = criterion(y_pred, y)\n","            predicted = torch.argmax(y_pred, 1)\n","            valid_acc += (y == predicted).sum().float()\n","            valid_losses += loss.item()\n","            valid_total += len(y)\n","            \n","'''\n","        wandb.log({\n","                'loss train': losses_train / len(train_iter),\n","                'accuracy train': accuracy_train / total_train,\n","             \n","                'valid loss aug': valid_losses_aug / len(train_valid_iter),\n","                'valid accuracy aug': valid_accuracy_aug / valid_total_aug,\n","            \n","                'valid loss': valid_losses / len(valid_iter),\n","                'valid accuracy': valid_acc / valid_total\n","        })\n","'''            \n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T14:21:10.627610Z","iopub.status.busy":"2024-01-21T14:21:10.627227Z","iopub.status.idle":"2024-01-21T14:21:10.634068Z","shell.execute_reply":"2024-01-21T14:21:10.632959Z","shell.execute_reply.started":"2024-01-21T14:21:10.627577Z"},"trusted":true},"outputs":[],"source":["classes = ['airplane',\n","'automobile', \n","'bird', \n","'cat', \n","'deer', \n","'dog', \n","'frog', \n","'horse', \n","'ship', \n","'truck']"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T14:26:31.942514Z","iopub.status.busy":"2024-01-21T14:26:31.942099Z","iopub.status.idle":"2024-01-21T14:29:03.511612Z","shell.execute_reply":"2024-01-21T14:29:03.510476Z","shell.execute_reply.started":"2024-01-21T14:26:31.942468Z"},"trusted":true},"outputs":[],"source":["with torch.no_grad():\n","    pretrained_net.eval()\n","    test_pred = torch.LongTensor()\n","    for i, data in enumerate(test_iter):\n","        img,_ = data\n","        img = img.to(device)\n","        output = pretrained_net(img)\n","        output = torch.argmax(output, 1)\n","        output = output.cpu()\n","        test_pred = torch.cat((test_pred, output), dim=0)\n","        \n","label = []\n","for i in test_pred:\n","    label.append(classes[i.item()]) \n","    \n","ids = [i for i in range(1,len(label)+1)]\n","out = {\"id\": ids, 'label': label}\n","out = pd.DataFrame.from_dict(out)\n","out.to_csv('submision.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":46718,"sourceId":3649,"sourceType":"competition"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
